算法有很多，可以直接用来推荐，也可以作为召回的一个通路，采用多模块最终推荐。

召回模型是负样本的艺术，排序模型是特征的艺术。

# 矩阵分解做召回

使用矩阵分解召回

角色：从百万甚至十亿量级的全量物品库中，快速、粗略地筛选出几百到几千个可能相关的候选物品。

如何使用MF做召回：

训练：使用用户-物品交互数据（如点击、购买）训练MF模型，得到：

用户隐向量：user_embedding

物品隐向量：item_embedding

在线服务：

为每个用户计算user_embedding

使用近似最近邻搜索库（如FAISS, Annoy, HNSW）在所有item_embedding中快速查找最相似的Top-K个物品。

这些物品就是召回结果。

优点：

MF能有效捕捉用户和物品的广义兴趣关联。

基于向量的检索效率极高，能满足毫秒级响应的要求。

注意：在实际系统中，我们通常会设置多个召回通道，MF只是其中之一。还可能包括：

热门召回：返回近期最热门的物品。

协同过滤召回：基于Item-CF或User-CF。

基于内容的召回：根据用户最近喜欢的物品属性（如类别、作者）找相似的。

地理召回：召回附近的物品或服务。

多个召回源的结果合并后，共同送入排序阶段。

# ANN算法

ANN 的全称是 Approximate Nearest Neighbor Search，中文是近似最近邻搜索。

精确最近邻搜索：给定一个查询点（比如一个用户向量），在巨大的数据库（比如所有物品的向量）中，100%准确地找出距离它最近的那个点（最相似的物品）。

近似最近邻搜索：我们不要求100%的准确，允许返回的结果可能不是“绝对最近”的，而是“足够近”的邻居。作为交换，搜索速度会极大地提升，并且占用更少的内存。

核心原理：

1、将整个高维向量空间切割成多个更小的、互不重叠的子区域（桶），并建立索引。比如局部敏感哈希

2、原理：将每个数据点视为图中的一个节点，并构建一张图，图中每个节点都连接到它的“近邻”节点。比如HNSW算法

在一个典型的推荐系统中，ANN扮演着“召回”阶段的核心角色。

向量化：

使用模型（如深度学习模型、矩阵分解）将用户和物品转化为同一向量空间中的向量（Embedding）。

用户向量：代表用户的兴趣。

物品向量：代表物品的特征。

构建索引（离线）：

将所有物品向量预先构建成一个ANN索引（比如使用HNSW算法），并存入数据库。

召回（在线）：

当用户访问App时，系统实时计算出该用户的用户向量。

将这个用户向量作为查询点，送入ANN索引中。

ANN索引迅速返回几百个（例如500个）最相似的物品向量对应的物品ID。这个过程就是“召回”。

排序：

将召回得到的500个物品，送入一个更复杂、更精细的排序模型中，综合考虑用户历史、物品热度、上下文特征等，进行精准打分。

排序模型会输出一个最终的、按分数排序的Top-N列表（比如20个），展示给用户。

总结一下：ANN负责海选，排序模型负责精选。


神经网络/深度学习推荐算法类型：

1、基于协同过滤的深度模型

NeuMF（神经矩阵分解）、DeepCF、

2、基于自编码器的模型

AutoRec、变分自编码器推荐系统（VAE-CF）

3、基于序列建模的模型

GRU4Rec、Caser、SASRec

4、基于特征交叉的深度模型

Wide & Deep、DeepFM、xDeepFM

5、基于图神经网络的模型

NGCF（神经图协同过滤）、LightGCN