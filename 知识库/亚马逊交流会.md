# 收获

1、原先做法，我们是去做一个拟人模型，去掉大模型助手的那种感觉，但是亚马逊分析后直接从业务目标出发，业务上需要扮演1000个角色，每个小模型（7B）只能扮演最多10个角色



# 线下交流



1、虚拟女友一期

prompt破限

lora微调会导致角色拟合较差，全参sft可以解决，但参数量大

十几-几十轮对话，4k条

旁白描述为第一人称

不同风格对话改写，8\*500，claude3效果更好（热情、冷酷、等等）

提示词模板：sys+user+assistant

新加角色还是需要重新微调，效果会更好



nfsw中的开放程度是通过提示词设计好了



2、虚拟女友二期

构造数据的提示词

生成50-100轮对话，丰富度、claude。共1685条数据（每轮共50-100个对话）

**十几条规则+场景+描述**

角色知识的退化

一个7b对应能容纳的角色数量不多，因为模型能力不够，更大的模型可以。



项目周期：3-4周一个循环，2周一个打分

具体的清晰好我们的使用用户的人群，角色越清晰越好，然后再去构造数据







Whisper-subtitle-summary-webui







# 2-28线上第一次交流

## 亚马逊对任务理解

不符合角色设定

缺少对话历史记忆

没有图片发送的能力



## RAG检索

历史记录数据库，rag检索模块获取相似话题，低于0.9，不采纳，

技术方案：

Rag检索模块



## 对话分类

初始对话、claude对话



## 数据构造



# 线上第一次交流

系统提示词：

角色信息、系统提示词的其他要求

用户和角色进行对话



# 2-28第二次

带检索的对话生成，user1+user2（rag），对话到50轮，然后进行训练

通过训练得到角色扮演能力+图片回复能力。

user2在训练时会检索历史记录，放到训练数据中。



下一步：

模拟更多数据，采用ds或3.7等

需要记忆什么事情？

模型训练和效果评估





问题：

如何去评估这个数据质量，**拟人很重要，如何生成？**

用deepseek生成一个场景，剧情大纲，然后生成剧情对话聊天历史，然后辅助用来训练



多语言是否有更大的难度？**中文+英语训练，然后支持多语种推理。那边老师比较有信心。**

生成的数据需要更多的讨论。

13b或14b训练，速度没问题，1s几十个token



数据构造问题，一轮一轮





# 3-7第三次

生成数据时：

对话目的  跟我的关系字段，没有放进去



全部都是claude3.7生成的

场合，情境的关系，问题

目前定的是qwen14b，32b或70b也可以去尝试



微调的意义？



场景+话题 -->人物生成

角色过于贴合，与，角色完全不贴合，这个度很难掌握

用户会引导问题的转换



尽快：使用ds来生成数据，训练其他的模型如qwen7B



# 3-14第四次

主选 和 备选方案，心里要有预期

微调的上限就是PE提示词方案



# 3-21第五次

多agent模拟对话：

角色1+角色2+场景话题agent+主持人agent



角色扩充：中外历史+共580多种角色

10+角色

20\*30=600组对话



user知道bot的角色信息，bot不知道user的角色信息，双方都知道对话情景信息

训练时system中没有放情景信息



主持人只做一件事情：当前会话是否应该停止。



目前知识边界做的不够好



泛化性，10个角色数据效果较差，要混合其他角色的数据

通过训练更多的角色来达到更好的泛化性

一个模型需要多少数据量，



喂多少token，loss下降多少，对应比例再下降，就说明该停止了



系统提示词的效果需要测试



通过更强的模型来打标，dpo



TODO：

1、尝试



亚马逊的思想：32b模型训练50个角色，然后利用模型的泛化能力去覆盖100个角色

这里比我的原先思路要好很多：我的思路是用20个32b模型训练1000个角色，这个成本太高了。





# 3-28 待沟通事项：

## 本周2反馈的问题：

**1、虚拟人挑起话题和延展用户话题持续沟通的能力**

**2、虚拟人聊天时预设了场景**

**3、虚拟人回复的多样性**



## 后续需要改进的问题：

**1、语种需要严格一致**

即，不管用户说什么语言，每个虚拟人的说话语种统一为虚拟人自身设定好的语种

**2、训练数据是否有必要引入function calling**

必要性在于：统一范式，后面新增功能比较好接入

①支持图片生成、视频生成

②记忆检索

③知识检索

**3、微调数据量需要达到多少？是否还需要额外做一些安全对齐的数据来微调**



1、用户聊天时，如何做意图识别

训练数据构造时，**加上cot**，识别意图。

2、延续话题，深入话题，发起话题

反问的形式不佳，通过虚拟人不断抛话题然后用户与之聊天

3、从用户发送的消息中提取记忆，

①维护一个信息persona

②上下文History入库，rag检索

③模型自己去判断可能对模型能力要求较高，人为去检索效果可能可行

4、表情包

通过一个表情库来设定

5、虚拟人的特长

新进来的人设定开场白

引导用户往自己擅长领域去聊，另外就是真的擅长

6、增加新的话题

产品目前：**most 3 问题 :**

**延展性、深度、话题**

**虚拟人对用户的记忆**

**虚拟人的能力、知识边界问题**



前期用户轮数不多，rag可以暂时不考虑

调整数据

试一下sys prompt，换一下角色

接入图片，等一下亚马逊开通文生图模型

多测试，多发现问题

# 方案

1、修改提示词，让虚拟人更加主动，保持话题延展和深入

2、允许虚拟人回复多句话

## 4-14

多语言的问题需要重新构造训练数据，

32b模型提升了多语言的能力后会损失聊天能力吗？不会！

翻译

**训练时最大token数可以为8196**

语言

