https://zhuanlan.zhihu.com/p/685823865

https://zhuanlan.zhihu.com/p/719135803

https://zhuanlan.zhihu.com/p/719772276



**角色扮演做的事情是和用户一起完成某个虚拟情节的构建，而且inner thought很重要！！！**

我有时候甚至觉得，角色扮演对标的与其说是真人聊天，不如说是galgame。**或者说，角色扮演模型做的事情是「和用户一起完成某个虚拟情节的构建」。在这个过程中，角色扮演模型的输出不仅是角色「说的话」，在某种程度上也充当了「旁白」的角色。这再次证明了「描述性文本」的重要性。**

所以，这就是为什么很多人会用小说、剧本中抽取的内容来训练SFT。

所以，这就是为什么如果直接用小说、剧本抽取对话来训练通常不太work。（后边会展开讲实验）

**直接从小说中抽人物对话会导致一个问题，那就是小说人物对话可能非常短，有时候甚至只有一两个字，更多的信息如角色的心理活动等放在旁白里进行描写了。如果只使用角色说的话来训练的话，会导致「信息缺失」。**



**当我们聊角色扮演的时候不是一问一答助手类的角色扮演，而是有来有回的真人扮演**

本质还是一问一答助手类的角色扮演：

「请你扮演一个翻译专家」「请你扮演一个程序员」这种任务类“角色扮演”

「请你扮演张飞：请告诉我你作为刘备的部下如何评价他的处事准则」这种辣鸡问答，

**本质上还是一个assistant助手**



真正的角色扮演应该是类似真实人类的对话，永远都不会是刻板的一问一答，而是有来有回的碰撞。



**如何评价角色扮演回复的效果？**

作为一个真实的人或角色，通常都会有一个明确的立场，所以永远都不会说”因人而异“这种端水类的话术；

作为一个真实的人或角色，通常都会缺点有小心机，所以从来不会像chatGPT一样永远一本正经讲大道理；

作为一个真实的人或角色，通常都会有自己的性格和脾气，所以从来都不会像正常底座模型一样有问必答；

作为一个真实的人或角色，从来都不会说「作为xxx，我认为......」这种奇怪的话。

那这个问题怎么解决呢？我目前的做法是简单粗暴建立一个**黑名单词表**，把所有带强烈违和感或真实人类根本不会说的词给过滤掉。

那怎么快速评价模型输出是否有违和感呢？或者换个角度，什么样的输出算是一个没有违和感的模型呢？

我的方法就是：把模型输出结果中所有的「我」这个字替换成「角色名」，看这句话是否成立。如果成立，则认为有违和感，即模型并没有真正带入角色，只是在输出形式上做到了角色扮演而已；如果不成立，那我们认为当前模型输出质量基本达标。



**小说续写创作而非继续预训练**

写作能力和角色扮演能力确实强相关，也就是说：有角色扮演需求的用户大概率也会有小说创作的需求。



**底座模型能力退化与对话能力的矛盾**

因为前面我们提到，通用问答模型具有很强的assistant语气，这必然会导致角色扮演任务的违和感。那太小的学习率，会导致模型更难以学到新知识；太大的学习率又容易灾难性遗忘。如何找到平衡点是一个很玄学的问题。如果你想采用一个更高的学习率，那这里可以参考Qwen技术报告，适当增大warmup ratio（但一定要保证数据量足够多），个人实验结果还不错。



**微调到底能解决什么？**

微调和Prompt都能实现角色扮演，微调主要解决说话风格的拟人化，因为Prompt方案基本上就能回答好角色本身的一些事实知识或者经历的问题。

但是尴尬的是，大多数微调产品都超越不了Prompt方案的说话风格/拟人程度。



**强化学习思路**

do sample，infer多条结果，打分，构建pair

我的思考：利用SFT训练一个基础的LLM，然后开始角色扮演推理，多次采样，得到很多结果，然后构造好打分函数来打分，最终进行pair构建。

