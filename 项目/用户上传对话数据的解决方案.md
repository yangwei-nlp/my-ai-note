# 方案选型

时间：2025-7-15

1、数据清洗得到整齐的说话模版，和人设信息共同组成system message

**思想**：主要通过模型本身来理解对话数据并在回复时以此数据为参考

**特点**：无需训练，集成速度快

**适用范围**：用户上传数据量少，大多数产品都是这个方案



2、数据送入RAGflow知识库，每次回复从中召回相似语句

**思想**：本质还是通过模型本身来理解对话数据从而回复，只是多了RAG召回

**特点**：无需训练，但需接RAG系统较繁琐；效果和方案1接近

**适用范围**：大多数用户都上传对话数据，且上传数量大。此方案被很多Agent、coze工作流和智能体在使用



3、在线LoRA微调或RL微调

**思想**：对模型本身进行小参数的高效微调

**特点**：对模型本身进行微调，理论上效果最好，但成本也最高；多LoRA挂载对推理速度没影响，但加载LoRA耗时100ms内；理论上LoRA模块数量可以很大（取决于内存和显存）。

**适用范围**：用户上传数量特别大（每个用户100条会话以上）

**具体方案**：

①单用户单权重，每次聊天加载LoRA权重；特点：**动态加载LoRA，初始耗时增加不到100ms**。

②**一个国家/职业/性格一个LoRA权重**，每次上传对话数据就更新该LoRA权重。

**机器要求**：至少80GB显卡机器常驻运行（排队进行LoRA）



# 阶段性目标

1、验证可行性，包括算力验证、步骤验证和延时验证

2、以单个人的训练为例，提供演示demo和评估文档

3、训练5个人左右的lora，提升性格和职业能力，提供demo和评估文档

4、在基模上提升在特定场景下的角色扮演能力





# 阶段性进展

1、可行性验证结论

算力验证：当前框架下4卡24G算力不可行，其他框架需进一步研究

步骤验证：可行

延时验证：可行。训练在小时级别，训练好了后加载和卸载参数都在几十毫秒级别，推理在秒级别。



2、整理好124条郭德纲的数据，格式对齐后再进行训练

时间：2025-7-25

预计：2025-7-29训练郭德纲的对话数据，并提供demo和评估文档







公众人物 or 自定义人物

